[32m[I 2025-07-06 22:32:09,831][0m A new study created in RDB with name: maddpg_balance_tuning_wandb_2[0m
--------------------------------------------------
Episode: 500, average_score: -39.24, delta: -39.24
--------------------------------------------------
/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/Distill.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.states = T.stack([T.tensor(s[agent_idx], dtype=T.float32) for s, _ in data])
/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/Distill.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.actions = T.stack([T.tensor(a[agent_idx], dtype=T.float32) for _, a in data])
Trial 0 failed: 'Net' object has no attribute 'save_checkpoint'
[33m[W 2025-07-06 22:44:31,636][0m Trial 0 failed with parameters: {'buffer_size': 100000, 'hidden_dim': 512} because of the following error: The value nan is not acceptable.[0m
[33m[W 2025-07-06 22:44:31,636][0m Trial 0 failed with value nan.[0m
--------------------------------------------------
Episode: 500, average_score: -43.01, delta: -43.01
--------------------------------------------------
Trial 1 failed: 'Net' object has no attribute 'save_checkpoint'
[33m[W 2025-07-06 23:04:25,125][0m Trial 1 failed with parameters: {'buffer_size': 100000, 'hidden_dim': 128} because of the following error: The value nan is not acceptable.[0m
[33m[W 2025-07-06 23:04:25,126][0m Trial 1 failed with value nan.[0m
--------------------------------------------------
Episode: 500, average_score: -24.67, delta: -24.67
--------------------------------------------------
[33m[W 2025-07-06 23:15:12,091][0m Trial 2 failed with parameters: {'buffer_size': 100000, 'hidden_dim': 256} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/tuning.py", line 93, in objective
    result = train(env=env, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/main.py", line 121, in train
    maddpg_agents.learn(memory)
  File "/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/MADDPG.py", line 95, in learn
    action = agent.actor[actor_idx].forward(state)  # Let the actor re-act
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/Networks.py", line 53, in forward
    x = F.relu(self.fc1(state))
               ^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[33m[W 2025-07-06 23:15:12,097][0m Trial 2 failed with value None.[0m

Number of finished trials: 3

Best trial:
Traceback (most recent call last):
  File "/Users/brian/Reinforcement_learning/Luciano/RL_Multi_Agent/tuning.py", line 160, in <module>
    trial = study.best_trial
            ^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/study/study.py", line 155, in best_trial
    return self._get_best_trial(deepcopy=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/study/study.py", line 307, in _get_best_trial
    best_trial = self._storage.get_best_trial(self._study_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/storages/_cached_storage.py", line 180, in get_best_trial
    return self._backend.get_best_trial(study_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py", line 914, in get_best_trial
    trial_id = models.TrialModel.find_max_value_trial_id(study_id, 0, session)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/brian/miniconda3/envs/RL/lib/python3.11/site-packages/optuna/storages/_rdb/models.py", line 211, in find_max_value_trial_id
    raise ValueError(NOT_FOUND_MSG)
ValueError: Record does not exist.
